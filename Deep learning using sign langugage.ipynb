{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "385e43a763cf2a2e696526612151db7c079f8909"
   },
   "source": [
    "# Sign Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2586e6624621731384bd5dda484058cedb8bf859",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"../input/amer_sign2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7edbefdee7d8c7ec18be7f29ca2cb9180399b75b"
   },
   "source": [
    "# About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fed611598feffec2b2024c5dcf4fd057b6e2d1eb"
   },
   "source": [
    "The original MNIST image dataset of handwritten digits is a popular benchmark for image-based machine learning methods but researchers have renewed efforts to update it and develop drop-in replacements that are more challenging for computer vision and original for real-world applications. As noted in one recent replacement called the Fashion-MNIST dataset, the Zalando researchers quoted the startling claim that \"Most pairs of MNIST digits (784 total pixels per sample) can be distinguished pretty well by just one pixel\". To stimulate the community to develop more drop-in replacements, the Sign Language MNIST is presented here and follows the same CSV format with labels and pixel values in single rows. The American Sign Language letter database of hand gestures represent a multi-class problem with 24 classes of letters (excluding J and Z which require motion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "43610b28fcb6c9bd7cb7faf5e16b5b7036e2d63e"
   },
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bbcbb713210c674a54142d4ade11072985c94754",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "39cff8696636f21dd5b26854b6d608a73a635345",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/sign_mnist_train.csv')\n",
    "test = pd.read_csv('../input/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1704cf375513a33e8c0d963feebca7b783b5a0b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c2df551d7a771cb4fdc25b574a48a1652f251f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "81fbe2142a6a125bb488c4855e10627537c326ee"
   },
   "source": [
    "The data set is given in the form of labels and pixel value ranging from pixel 1 to pixel 784 which is 28 * 28 image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5c6e4b42bd30787413c5a36b1d6a3dd2c0bd76f"
   },
   "source": [
    "Let's see what does each sign means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "20bf62e3f3bd4132b3334e4351182b9f95dd3f1f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(\"../input/american_sign_language.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b4e745e346f02d6cae12b2518281311c947aab3",
    "collapsed": true
   },
   "source": [
    "Each letter indicates a sign produced by our fingers. We will apply deep learning to these images to make sure our model can understand what sign indicated what letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c08c24f5b0f18610feb7fbf0d7772792f78dac8d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b97bf1309270da6695095e295886882e8c3c8af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_val = np.array(labels)\n",
    "np.unique(unique_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46e4bfa083095d0ee14048250875952381d7060b"
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7f35db6e0ad4d62e93e82d932dea132ccd17d361",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "sns.countplot(x =labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2806c29690539d6c1fad7a1c3e0aad98656e000"
   },
   "source": [
    "As you can see each one is almost equally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf73d03f610be9f134a3ee5e35301b1da4626d02",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop('label', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4132dc4a950e5789e26dbc1f62d9e98c588ed6ee"
   },
   "source": [
    "We are droping the label coloumn from the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70c52bd461c45292cfda21aff61154009214e281"
   },
   "source": [
    "Re shaping the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b25a4af6ed60a970d5f530f4c94aca2e0c2554de",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = train.values\n",
    "images = np.array([np.reshape(i, (28, 28)) for i in images])\n",
    "images = np.array([i.flatten() for i in images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d80e740885bcf787ceffd6fb2de2d7f47df6710",
    "collapsed": true
   },
   "source": [
    "Since our target variable are in categorical(nomial) so we are using label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "796cf96b649f38bdece4403bf719e5788857f296",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binrizer = LabelBinarizer()\n",
    "labels = label_binrizer.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e6e3147f9d104a39ca91b75e5e78d44b07b9b35",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d73108efa38f76b1fb2da496a623a1fc70a4c53f"
   },
   "source": [
    "Lets see how the images look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3381e5155295c437768c05889ac3fe5b449a1c7d",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba7bfbf01786a077db6287f795469308e2e37044"
   },
   "source": [
    "Spliting the dataset into train(70%) and test(30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2998dd21e53a4f15514277995491eafc5f6b235",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8195b569b6b66f7f03d510b26eb8941a6eff8f96",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5cf6d05ff905388db8f1e30755e0df361d4334c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca7ff22abf6130778af7ec7e8c1062365b1a5179",
    "collapsed": true
   },
   "source": [
    "For deep learning i am using keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ec82309ac0cd088766cfccd095401d706c09462",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d6db165b0ca7701969b6ab373182e475dfdf8c9"
   },
   "source": [
    "Creating the batch size to 128 and using 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4321e7c0755b03a7ed072cab088d02b27f3f734f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 24\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "642c57023e8cc89f7ec0d90c16ffa3c4c3db78f6"
   },
   "source": [
    "Normalizing the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c844dbe8b17ca2926268369d41b2973ffe5e9070",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cb372496acf0b6e5ffb4a951d4445929fed7706",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c557ee15f0f647690965549ce66a64645a91829",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09645baa07e52c8dc13b386764ed84b6f23a1078"
   },
   "source": [
    "Visualizing the image after normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9556ccbe5f61082d473f9fbafa1f741e8767a496",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82f51a8ea917e21a1059c8e02c38c6a73ff7e994"
   },
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31b10d7abd4b28e7de20a46bab97b87bdf797fdb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(28, 28 ,1) ))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3f7e5cbaf7fd6a0b87cbaa2a91febc373fa41ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8017080980e9d0e1a97782e518e502ba3e71b13",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb2775e7f90958e544d84c476bcb52bd985e6395",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "364ebc9e410934e1ce04aee1052255d70a25c0fc"
   },
   "source": [
    "As you can see, the number of epochs increase the accuracy also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2de69255c5eeb26335a39f39ff2efb307eeb405",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f16f3a253826a51b7ad38bb2576bf200173581f"
   },
   "source": [
    "Let's validate with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e486c080ea745082f91ca1d2cfc0aac975afdd3b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "928db66ba635ba5cfc2726d8999221b40ccb65c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop('label', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7784e23a832e38afafcf619b779a43f10a1ff324",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test.values\n",
    "test_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\n",
    "test_images = np.array([i.flatten() for i in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7b3c7af0b9d568322311fce747bf9e6dc38a7e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = label_binrizer.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3ce64a4b948d953cfb30bfee2da40c91c097149",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f052e644cc78e783b928c28f2fdaf489d02db2a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e4a7b58496038c7d5b33b30e5039cd6f283369e"
   },
   "source": [
    "Predecting with test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27670fc85328b772e9cf2446f091be92bf85c44b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "338856c7e654588d95949cac42bdec5e9764577c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eeb5aed5bf49f586df371798cb0bd25f437f60de",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_labels, y_pred.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c06ce8efc9b99d13dd90e13f899e3cfa00f39fd8",
    "collapsed": true
   },
   "source": [
    "As we can see we got a really great accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a85cd666be3a99bb26c97f7fde9d35d5155ed204",
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9eb678647d643867930b4beb7135672ac811fdb4",
    "collapsed": true
   },
   "source": [
    "We can increate the accuracy by tuning the hyper parameters of the model like playing with different activation functions and using different loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ea8e028946c030cc36a7bab5eb0e2c0dd8eb84c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
